# Logging: Advanced Details

## MultiEventLog

The `MultiEventLog` is intended to be configurable to exclude unnecessary
information, and to include any built-in or user-defined metrics. It stores a
set of "sub-log" streams internally, appending a single element to each of them
when an event is generated. This element can be called a "sub-event" (to
distinguish it from the higher-level "event" that Dagger creates), and is
created by a "consumer". A consumer is a function or callable struct that, when
called with the `Event` object generated by TimespanLogging, returns a sub-event
characterizing whatever information the consumer represents. For example, the
`Dagger.Events.BytesAllocd` consumer calculates the total bytes allocated and
live at any given time within Dagger, and returns the current value when
called. Let's construct one:

```julia
ctx = Context()
ml = TimespanLogging.MultiEventLog()

# Add the BytesAllocd consumer to the log as `:bytes`
ml[:bytes] = Dagger.Events.BytesAllocd()

ctx.log_sink = ml
```

As we can see above, each consumer gets a unique name as a `Symbol` that
identifies it. Now that the log sink is attached with a consumer, we can
execute some Dagger tasks, and then collect the sub-events generated by
`BytesAllocd`:

```julia
# Using the lazy API, for explanatory purposes
collect(ctx, delayed(+)(1, delayed(*)(3, 4))) # Allocates 8 bytes
log = TimspanLogging.get_logs!(ctx)[1] # Get the logs for worker 1
@show log[:bytes]
```

You'll then see that 8 bytes are allocated and then freed during the process of
executing and completing those tasks.

Note that the `MultiEventLog` can also be used perfectly well when using
Dagger's eager API:

```julia
ctx = Dagger.Sch.eager_context()
ctx.log_sink = ml

a = Dagger.@spawn 3*4
Dagger.@spawn 1+a
```

There are a variety of other consumers built-in to TimespanLogging and Dagger,
under the `TimespanLogging.Events` and `Dagger.Events` modules, respectively;
see [Dagger Types](@ref) and [TimespanLogging Types](@ref) for details.

The `MultiEventLog` also has a mechanism to call a set of functions, called
"aggregators", after all consumers have been executed, and are passed the full
set of log streams as a `Dict{Symbol,Vector{Any}}`. The only one currently
shipped with TimespanLogging directly is the `LogWindow`, and DaggerWebDash.jl
has the `TableStorage` which integrates with it; see
[DaggerWebDash Types](@ref) for details.

## LocalEventLog

The `LocalEventLog` is generally only useful when you want combined events
(event start and finish combined as a single unit), and only care about a few
simple built-in generated events. Let's attach one to our context:

```julia
ctx = Context()
log = TimespanLogging.LocalEventLog()
ctx.log_sink = log
```

Now anytime `ctx` is used as the context for a scheduler, the scheduler will
log events into `log`.

Once sufficient data has been accumulated into a `LocalEventLog`, it can be
gathered to a single host via `TimespanLogging.get_logs!(log)`. The result is a
`Vector` of `TimespanLogging.Timespan` objects, which describe some metadata
about an operation that occured and the scheduler logged. These events may be
introspected directly, or may also be rendered to a DOT-format string:

```julia
logs = TimespanLogging.get_logs!(log)
str = Dagger.show_plan(logs)
```

`Dagger.show_plan` can also be called as `Dagger.show_plan(io::IO, logs)` to
write the graph to a file or other `IO` object. The string generated by this
function may be passed to an external tool like `Graphviz` for rendering. Note
that this method doesn't display input arguments to the DAG (non-`Thunk`s);
you can call `Dagger.show_plan(logs, thunk)`, where `thunk` is the output
`Thunk` of the DAG, to render argument nodes.

!!! note
    `TimespanLogging.get_logs!` clears out the event logs, so that old events
    don't mix with new ones from future DAGs.

As a convenience, it's possible to set `ctx.log_file` to the path to an output
file, and then calls to `compute(ctx, ...)`/`collect(ctx, ...)` will
automatically write the graph in DOT format to that path. There is also a
benefit to this approach over manual calls to `get_logs!` and `show_plan`: DAGs
which aren't `Thunk`s (such as operations on the `Dagger.DArray`) will be
properly rendered with input arguments (which normally aren't rendered because
a `Thunk` is dynamically generated from such operations by Dagger before
scheduling).

## FilterLog

The `FilterLog` exists to allow writing events to a user-defined location (such
as a database, file, or network socket). It is not currently tested or
documented.
